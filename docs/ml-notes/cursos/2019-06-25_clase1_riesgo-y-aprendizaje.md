# 2019-06-25 â€“ Riesgo y aprendizaje estadÃ­stico (clase 1)

**Fuente:** `raw/scans/MECA MACHINE LEARNING NOTES.pdf`, pÃ¡ginas 1â€“6.

## 1) TerminologÃ­a y tipos de aprendizaje

En los apuntes se separa el trabajo en:

- **Supervisado**: tienes variable objetivo `Y` y covariables `X`. Objetivo: aprender una funciÃ³n `f` que prediga `Y` con buen desempeÃ±o fuera de muestra.  
  Ejemplos tÃ­picos (y donde he visto dinero real): *scoring*, fraude, collections, churn, demanda.

- **No supervisado**: solo observas `X` y buscas estructura.  
  Ejemplos: segmentaciÃ³n, clustering, reducciÃ³n de dimensiÃ³n, detecciÃ³n de anomalÃ­as.

- **Semi-supervisado** (aparece mencionado): parte de los datos tiene etiqueta, parte no.

- **Aprendizaje por refuerzo** (mencionado): decisiones secuenciales con recompensa.

**ProducciÃ³n (2025â€“2026):**  
- Supervisado domina *pricing, riesgo, fraude, forecasting*.  
- RL se usa mÃ¡s en **recomendaciÃ³n / bidding / routing** y *supply chain* cuando hay simuladores o logs suficientes; sin eso suele quedarse en papers.

## 2) FormalizaciÃ³n del problema de clasificaciÃ³n

Dataset:
\[
T=\{(x_1,y_1),\dots,(x_n,y_n)\},\quad (X,Y)\sim P(X,Y),\quad y\in\{0,1\}.
\]

Espacios:
- `X âˆˆ ğ’³` (en los apuntes: algo como `â„^p`).
- `Y âˆˆ {0,1}`.

FunciÃ³n/hipÃ³tesis:
\[
f:\mathcal{X}\to \{0,1\}.
\]

**Loss (0â€“1):**
\[
L(y,f(x))=\mathbb{I}(y\neq f(x)).
\]

## 3) Riesgo: lo que importa vs lo que se estima

- **Riesgo verdadero (generalizaciÃ³n):**
\[
R(f)=\mathbb{E}[L(Y,f(X))].
\]

- **Riesgo empÃ­rico (entrenamiento):**
\[
\hat{R}_n(f)=\frac{1}{n}\sum_{i=1}^n L(y_i,f(x_i)).
\]

En producciÃ³n, el â€œriesgoâ€ no es abstracto: casi siempre es **pÃ©rdida econÃ³mica esperada**.

Ejemplos de â€œriesgo = negocioâ€:
- Fraude: `R` â‰ˆ coste de FP (rechazar bueno) + coste de FN (dejar pasar fraude) + fricciÃ³n.
- CrÃ©dito: `R` â‰ˆ pÃ©rdida esperada (EL = PDÃ—LGDÃ—EAD) + coste de capital + coste de adquisiciÃ³n.

> He visto modelos con +0.02 AUC que *perdÃ­an* dinero porque movÃ­an la frontera de decisiÃ³n sin tener en cuenta costes asimÃ©tricos y capacidad operativa.

## 4) Clasificador Ã³ptimo de Bayes (idea central)

Para pÃ©rdida 0â€“1, el Ã³ptimo es:

\[
f^\*(x)=\mathbb{I}\big(P(Y=1\mid X=x)\ge 0.5\big)
\]

(misma idea que aparece en los apuntes).

**Por quÃ© importa:** Bayes te dice que el â€œlÃ­miteâ€ es estimar bien la probabilidad condicional. Todo el resto son aproximaciones con sesgo/varianza.

## 5) â€œCaballitos de batallaâ€ del curso

### 5.1 k-Nearest Neighbors (k-NN)

Procedimiento (en los apuntes):
1. Para un `x` nuevo, busca los `k` vecinos mÃ¡s cercanos (segÃºn una distancia).
2. Predice por mayorÃ­a (clasificaciÃ³n) o promedio (regresiÃ³n).

**ProducciÃ³n (realista):**
- k-NN puro casi nunca entra a producciÃ³n por **latencia** (bÃºsqueda de vecinos) y **mantenimiento**.
- SÃ­ aparece como **bloque**: recuperaciÃ³n de candidatos (ANN), embeddings + bÃºsqueda aproximada, â€œsimilarity featuresâ€.

### 5.2 Modelo lineal (para clasificaciÃ³n/regresiÃ³n)

HipÃ³tesis lineal:
\[
f(x)=\beta^\top x.
\]

Para clasificaciÃ³n, se usa un umbral (en el cuaderno se menciona 0.5).

**2025â€“2026:** lo lineal sigue siendo brutalmente Ãºtil por:
- Interpretabilidad (auditorÃ­a / SR 11-7 / reguladores).
- Coste y latencia bajÃ­simos.
- Buen rendimiento con buen feature engineering.

## 6) Bias vs variance (lo que te va a romper en prÃ¡ctica)

En el cuaderno aparece la separaciÃ³n:
- **Error de aproximaciÃ³n (sesgo)**: tu clase de modelos no puede representar la verdad.
- **Error de estimaciÃ³n (varianza)**: con datos finitos, estimas mal.

**Regla que pago con sangre:**  
> â€œMÃ¡s complejoâ€ casi siempre baja el error de train, pero **no** garantiza bajar el error fuera de muestra.

En `docs/resumos-tematicos/bias-variance-tradeoff.md` dejo una versiÃ³n *operativa* (quÃ© mirar en curvas, cuÃ¡ndo parar, cÃ³mo monitorear).

## 7) Checklist de producciÃ³n (mÃ­nimo viable)

- Â¿QuÃ© es `Y` exactamente? (definiciÃ³n estable, sin leakage)
- Â¿QuÃ© ventana temporal usan las features?
- Â¿CÃ³mo se toma la decisiÃ³n? (threshold/estrategia)
- Â¿CuÃ¡l es el coste de FP vs FN? (matriz de costes)
- Â¿Necesito probabilidades calibradas o solo ranking?
- Â¿QuÃ© latencia y coste por predicciÃ³n tengo? (P95, P99)
- Â¿CÃ³mo monitoreo drift? (en `docs/resumos-tematicos/monitoreo-y-retraining.md`)
